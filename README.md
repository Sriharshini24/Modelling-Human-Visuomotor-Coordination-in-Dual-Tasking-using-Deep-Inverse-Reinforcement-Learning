[![Open in Colab](https://colab.research.google.com/assets/colab-badge.svg)](https://colab.research.google.com/drive/1EiK9IjsQqDq9hbtwngzoO7z62bH1qr1a#scrollTo=RR_pAuVrR2po)


This project focuses on modeling human visuomotor coordination during dual-tasking using Deep Inverse Reinforcement Learning (Deep IRL).

Visuomotor Coordination: This refers to the brainâ€™s ability to coordinate visual inputs with motor actions, essential for tasks requiring precise hand-eye coordination.

Dual-Tasking: Performing two tasks simultaneously, which challenges the cognitive and motor systems to manage and allocate attention effectively.

Inverse Reinforcement Learning (IRL): A technique where the goal is to infer the underlying reward function from observed expert behavior, rather than learning a policy directly.

DDeep IRL: Combines deep learning with IRL to handle complex, high-dimensional sensory inputs and extract the reward function that best explains observed human behavior.

In this project, Deep IRL is used to model and understand how humans coordinate their movements while managing two tasks at the same time, providing insights into cognitive and motor control mechanisms.
